# Big Data Hadoop Spark Developer Training

**Trainer :** Naveen




## Spark / PySpark

* [Spark and PySpark Environment Setup](https://docs.google.com/document/d/1KR4zTwI7TDzG3Irt0oH5DoQU9n5nHb5iUxlcoqjJpUs/edit?usp=sharing)
* Zeppelin Environment Setup
* [PySpark on Google Colab](https://blog.naveenpn.com/pyspark-on-google-colab)

## Configure PySpark Virtual Environment

```shell
cd c:/big-data-hadoop-spark-developer-training-simplilearn

# Create Virtual Environment
python -m venv venv
.\Scripts\activate
pip install -r requirements.txt
```

## Kafka

* Confluent Kafka Environment Setup

## AWS for Data Engineering

* [Putty Download](https://the.earth.li/~sgtatham/putty/latest/w64/putty.exe)
* [Puttygen Download](https://the.earth.li/~sgtatham/putty/latest/w64/puttygen.exe)
* [AWS CLI](https://awscli.amazonaws.com/AWSCLIV2.msi)
