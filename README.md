# Big Data Hadoop Spark Developer Training

**Trainer :** Naveen



## Software Essentials

* [Git Download](https://git-scm.com/downloads)
* [Local Development Environment Setup](https://docs.google.com/document/d/e/2PACX-1vR_mva3l81HrvbGeJOimo0MtssVVSGi4at3WYeRCHBeBAm319t3XivQCV97dhkpK1a5cSCUN7cdO3Sd/pub)
* [PyCharm IDE **Community Edition** Download](https://www.jetbrains.com/pycharm/download/#section=windows) 
* [Download DBeaver](https://dbeaver.io/download/)

## Spark / PySpark

* [Spark and PySpark Environment Setup](https://docs.google.com/document/d/1KR4zTwI7TDzG3Irt0oH5DoQU9n5nHb5iUxlcoqjJpUs/edit?usp=sharing)
* Zeppelin Environment Setup
* [PySpark on Google Colab](https://blog.naveenpn.com/pyspark-on-google-colab)

## Configure PySpark Virtual Environment

```shell
cd c:/big-data-hadoop-spark-developer-training-simplilearn

# Create Virtual Environment
python -m venv venv
.\Scripts\activate
pip install -r requirements.txt
```

## Kafka

* Confluent Kafka Environment Setup

## AWS for Data Engineering

* [Putty Download](https://the.earth.li/~sgtatham/putty/latest/w64/putty.exe)
* [Puttygen Download](https://the.earth.li/~sgtatham/putty/latest/w64/puttygen.exe)
* [AWS CLI](https://awscli.amazonaws.com/AWSCLIV2.msi)
